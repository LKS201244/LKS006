'''
é«˜è€ƒæ‹©æ ¡åŠ©æ‰‹ - æ™ºèƒ½èŠå¤©ç‰ˆ
'''
from openai import OpenAI, Stream
import streamlit as st
from typing import Generator, Optional

from openai.types.chat import ChatCompletion, ChatCompletionChunk

# å…¨å±€é…ç½®
PROVINCES = ['åŒ—äº¬', 'å¤©æ´¥', 'æ²³åŒ—', 'å±±è¥¿', 'å†…è’™å¤', 'è¾½å®', 'å‰æ—', 'é»‘é¾™æ±Ÿ', 'ä¸Šæµ·', 'æ±Ÿè‹', 'æµ™æ±Ÿ', 'å®‰å¾½', 'ç¦å»º', 'æ±Ÿè¥¿', 'å±±ä¸œ', 'æ²³å—', 'æ¹–åŒ—', 'æ¹–å—', 'å¹¿ä¸œ', 'å¹¿è¥¿', 'æµ·å—', 'é‡åº†', 'å››å·', 'è´µå·', 'äº‘å—', 'è¥¿è—', 'é™•è¥¿', 'ç”˜è‚ƒ', 'é’æµ·', 'å®å¤', 'æ–°ç–†', 'é¦™æ¸¯', 'æ¾³é—¨', 'å°æ¹¾']
SUBJECT_TYPES = ["æ–‡ç§‘", "ç†ç§‘", "ç‰©ç†ç±»", "å†å²ç±»", "æ–°é«˜è€ƒ"]
INTEREST_EXAMPLES = "å¦‚ï¼šè®¡ç®—æœºã€ä¸´åºŠåŒ»å­¦ã€é‡‘èå­¦ã€æ³•å­¦ã€å»ºç­‘å­¦"

def get_llm_response(
    client: OpenAI,
    model: str,
    user_prompt: str,
    system_prompt: Optional[str] = None,
    stream: bool = False
) -> ChatCompletion | Stream[ChatCompletionChunk]:
    """
    è·å–å¤§è¯­è¨€æ¨¡å‹å“åº”

    å‚æ•°:
        client: OpenAIå®¢æˆ·ç«¯å®ä¾‹
        model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        user_prompt: ç”¨æˆ·æç¤ºè¯
        system_prompt: ç³»ç»Ÿæç¤ºè¯(å¯é€‰)
        stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º

    è¿”å›:
        ç”Ÿæˆå™¨æˆ–å®Œæ•´å“åº”
    """
    messages = []
    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})
    messages.append({"role": "user", "content": user_prompt})

    return client.chat.completions.create(
        model=model,
        messages=messages,
        stream=stream
    )

def get_advice(question: str, score: int, province: str, interests: str, subject_type: str) -> Generator[str, None, None]:
    """
    æ™ºèƒ½ç”Ÿæˆé«˜è€ƒå¿—æ„¿å»ºè®®ï¼ˆæµå¼è¾“å‡ºï¼‰

    å‚æ•°:
        question: ç”¨æˆ·å’¨è¯¢é—®é¢˜
        score: é«˜è€ƒåˆ†æ•°(200-750)
        province: æ‰€åœ¨çœä»½
        interests: å…´è¶£ä¸“ä¸š
        subject_type: è€ƒç”Ÿç§‘ç±»

    è¿”å›:
        ç”Ÿæˆå™¨é€å—è¿”å›å»ºè®®å†…å®¹
    """
    try:
        # ä¸“ä¸šçº§æç¤ºè¯æ¨¡æ¿
        prompt = f"""ä½œä¸ºé«˜è€ƒå¿—æ„¿å¡«æŠ¥ä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹è€ƒç”Ÿä¿¡æ¯æä¾›ä¸“ä¸šå»ºè®®ï¼š
        
è€ƒç”Ÿæ¡£æ¡ˆï¼š
- æ‰€åœ¨çœä»½ï¼š{province}ï¼ˆéœ€è€ƒè™‘çœå†…å½•å–æ”¿ç­–ï¼‰
- é«˜è€ƒåˆ†æ•°ï¼š{score}åˆ†ï¼ˆ{_get_score_level(score)}ï¼‰
- æŠ¥è€ƒç§‘ç±»ï¼š{subject_type}
- å…´è¶£æ–¹å‘ï¼š{interests}
- å’¨è¯¢é—®é¢˜ï¼š{question}

è¯·æŒ‰ä»¥ä¸‹æ¡†æ¶å›ç­”ï¼š
1. åˆ†æ•°ç«äº‰åŠ›åˆ†æï¼ˆçœå†…æ’åé¢„ä¼°ï¼‰
2. æ¨èé™¢æ ¡æ¸…å•ï¼ˆåˆ†å†²åˆº/ç¨³å¦¥/ä¿åº•ä¸‰æ¡£ï¼‰
3. åŒ¹é…ä¸“ä¸šæ¨èï¼ˆç»“åˆå…´è¶£å’Œå°±ä¸šå‰æ™¯ï¼‰
4. å¿—æ„¿å¡«æŠ¥ç­–ç•¥å»ºè®®
5. é‡è¦æ³¨æ„äº‹é¡¹æé†’"""

        client = OpenAI(base_url=base_url, api_key=api_key)
        stream = get_llm_response(
            client=client,
            model=model_name,
            user_prompt=prompt,
            system_prompt="ä½ æ˜¯ä¸€åèµ„æ·±é«˜è€ƒå¿—æ„¿è§„åˆ’å¸ˆï¼Œå›ç­”éœ€ä¸“ä¸šå‡†ç¡®",
            stream=True
        )

        for chunk in stream:
            content = chunk.choices[0].delta.content or ''
            yield content

    except Exception as e:
        error_msg = f"âš ï¸ æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼ˆé”™è¯¯ä»£ç ï¼š{type(e).__name__}ï¼‰"
        yield error_msg

def _get_score_level(score: int) -> str:
    """åˆ†æ•°ç­‰çº§è¯„ä¼°"""
    if score >= 650: return "é¡¶å°–æ°´å¹³ï¼ˆå…¨çœå‰1%ï¼‰"
    elif score >= 600: return "ä¼˜ç§€æ°´å¹³ï¼ˆå…¨çœå‰10%ï¼‰"
    elif score >= 500: return "ä¸­ç­‰åä¸Š"
    elif score >= 400: return "ä¸­ç­‰æ°´å¹³"
    return "ä¸€èˆ¬æ°´å¹³"

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ™ºèƒ½é«˜è€ƒæ‹©æ ¡åŠ©æ‰‹",
    page_icon="ğŸ«",
    layout="centered"
)

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("ğŸ”§ ç³»ç»Ÿé…ç½®")
    api_vendor = st.radio(
        "AIæœåŠ¡æä¾›å•†",
        options=['OpenAI', 'deepseek'],
        index=0,
        horizontal=True
    )

    if api_vendor == 'OpenAI':
        base_url = st.selectbox(
            "APIç«¯ç‚¹",
            options=['https://api.openai.com/v1', 'https://twapi.openai-hk.com/v1'],
            index=0
        )
        model_options = ['gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo']
    else:
        base_url = 'https://api.deepseek.com'
        model_options = ['deepseek-chat', 'deepseek-v2']

    model_name = st.selectbox("AIæ¨¡å‹", options=model_options)
    api_key = st.text_input("APIå¯†é’¥", type="password", help="è¯·è¾“å…¥æœ‰æ•ˆçš„APIè®¿é—®å¯†é’¥")

    st.divider()
    st.header("ğŸ“‹ è€ƒç”Ÿæ¡£æ¡ˆ")
    user_score = st.slider(
        "é«˜è€ƒåˆ†æ•°",
        min_value=200,
        max_value=750,
        value=500,
        step=1,
        help="è¯·å¡«å†™çœŸå®é«˜è€ƒæˆç»©"
    )
    user_province = st.selectbox("æ‰€åœ¨çœä»½", options=PROVINCES, index=0)
    user_subject = st.radio("æŠ¥è€ƒç§‘ç±»", options=SUBJECT_TYPES, index=0, horizontal=True)  # ä¿®æ­£å˜é‡åæ‹¼å†™
    user_interests = st.text_area(
        "å…´è¶£ä¸“ä¸šæ–¹å‘",
        placeholder=INTEREST_EXAMPLES,
        help="å¯è¾“å…¥å¤šä¸ªä¸“ä¸šï¼Œç”¨é€—å·åˆ†éš”"
    )

# ä¸»ç•Œé¢
st.title("ğŸ¯ æ™ºèƒ½é«˜è€ƒæ‹©æ ¡åŠ©æ‰‹")
st.caption("AIé©±åŠ¨çš„å¿—æ„¿å¡«æŠ¥å’¨è¯¢ç³»ç»Ÿ | æ•°æ®ä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥å®˜æ–¹å‘å¸ƒä¸ºå‡†")

# åˆå§‹åŒ–å¯¹è¯
if 'messages' not in st.session_state:
    welcome_msg = """æ‚¨å¥½ï¼æˆ‘æ˜¯æ™ºèƒ½æ‹©æ ¡åŠ©æ‰‹å°é«˜ï¼Œè¯·å…ˆå®Œå–„ä¾§è¾¹æ çš„ï¼š
1. è€ƒç”ŸåŸºæœ¬ä¿¡æ¯
2. AIæœåŠ¡é…ç½®

ç„¶åå¯ä»¥ç›´æ¥æé—®ï¼Œä¾‹å¦‚ï¼š
- æˆ‘çš„åˆ†æ•°èƒ½ä¸Šå“ªäº›985å¤§å­¦ï¼Ÿ
- æ¨èé€‚åˆæˆ‘çš„è®¡ç®—æœºä¸“ä¸šé™¢æ ¡
- è¿™ä¸ªåˆ†æ•°åœ¨çœå†…çš„ç«äº‰åŠ›å¦‚ä½•ï¼Ÿ"""
    st.session_state.messages = [{"role": "ai", "content": welcome_msg}]

# æ˜¾ç¤ºå¯¹è¯å†å²
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# äº¤äº’å¤„ç†
if not api_key:
    st.warning("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥æœ‰æ•ˆçš„APIå¯†é’¥")
    st.stop()

if user_input := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    # éªŒè¯å¿…è¦ä¿¡æ¯
    if not all([user_province, user_subject, user_interests]):  # ä½¿ç”¨ä¿®æ­£åçš„å˜é‡å
        st.error("è¯·å…ˆå®Œå–„è€ƒç”ŸåŸºæœ¬ä¿¡æ¯ï¼")
        st.stop()

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "human", "content": user_input})
    st.chat_message("human").write(user_input)

    # è·å–å»ºè®®
    with st.status("ğŸ” æ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™...", expanded=True) as status:
        try:
            advice_gen = get_advice(
                question=user_input,
                score=user_score,
                province=user_province,
                interests=user_interests,
                subject_type=user_subject  # ä½¿ç”¨ä¿®æ­£åçš„å˜é‡å
            )

            # æµå¼è¾“å‡º
            response = st.chat_message("ai").write_stream(advice_gen)
            st.session_state.messages.append({"role": "ai", "content": response})

            status.update(label="âœ… åˆ†æå®Œæˆ", state="complete")
        except Exception as e:
            st.error(f"ç³»ç»Ÿé”™è¯¯: {str(e)}")